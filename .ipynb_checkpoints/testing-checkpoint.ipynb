{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "import chainerrl\n",
    "from chainerrl import explorers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "import sys\n",
    "from time import sleep\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "\n",
    "# COLORS\n",
    "white = (255, 255, 255)\n",
    "black = (0, 0, 0)\n",
    "red = (255, 0, 0)\n",
    "green = (0, 255, 0)\n",
    "blue = (0, 0, 255)\n",
    "purple = (255, 0, 255)\n",
    "\n",
    "# SIZES\n",
    "AGENT_SIZE = 50\n",
    "WEAPON_SIZE = 20\n",
    "\n",
    "class Entity:\n",
    "    def __init__(self, name, xy, angle, speed, game_dims=(1000,800)):\n",
    "        self.name = name\n",
    "        self.x, self.y = xy\n",
    "        self.speed = speed\n",
    "        self.angle = math.radians(-angle)  # -1 to 1 \n",
    "        self.dx = self.speed * math.cos(self.angle)\n",
    "        self.dy = self.speed * math.sin(self.angle)\n",
    "        self.dimx, self.dimy = game_dims\n",
    "        \n",
    "    def update(self, agent_xy):\n",
    "        self.x += self.dx\n",
    "        self.y += self.dy\n",
    "\n",
    "        agent_x, agent_y = agent_xy\n",
    "\n",
    "        has_hit_x = self.x >= agent_x - WEAPON_SIZE and self.x <= agent_x + AGENT_SIZE\n",
    "        has_hit_y = self.y >= agent_y - WEAPON_SIZE and self.y <= agent_y + AGENT_SIZE\n",
    "        \n",
    "        exit_boundary = self.x > self.dimx-50 or self.x < 000 or self.y > self.dimy-50 or self.y < 0\n",
    "\n",
    "        return has_hit_x and has_hit_y or exit_boundary\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.name + str((self.x,self.y))\n",
    "\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, xy=(400,100), game_dims=(1000,800), show=False):\n",
    "        self.jumps = 0\n",
    "        self.maxJumps = 2\n",
    "        self.xpos, self.ypos = xy\n",
    "        self.touchingObst = 0\n",
    "        self.gravityPull = 0.5\n",
    "        self.gravityCurrent = 0\n",
    "        self.xCurrent = 0\n",
    "        self.show = show\n",
    "        self.dimx, self.dimy = game_dims\n",
    "    def jump(self):\n",
    "        if self.jumps < self.maxJumps:\n",
    "            self.gravityCurrent = -10\n",
    "            self.jumps = self.jumps + 1\n",
    "    def left(self):\n",
    "        if self.touchingObst == 0:\n",
    "            self.xCurrent = -10\n",
    "    def right(self):\n",
    "        if self.touchingObst == 0:\n",
    "            self.xCurrent = 10\n",
    "    def update(self):\n",
    "        # CONTROL GRAVITY\n",
    "        self.gravityCurrent = self.gravityCurrent + self.gravityPull\n",
    "\n",
    "        # RATE OF DECREASE OF LEFT/RIGHT MOVEMENTS\n",
    "        if self.xCurrent > 0:\n",
    "            self.xCurrent = self.xCurrent - 0.5\n",
    "        if self.xCurrent < 0:\n",
    "            self.xCurrent = self.xCurrent + 0.5\n",
    "\n",
    "        # UPDATE XY COORDINATES\n",
    "        self.ypos = self.ypos + self.gravityCurrent\n",
    "        self.xpos = self.xpos + self.xCurrent\n",
    "\n",
    "        # BOUNDARIES\n",
    "        if self.xpos > self.dimx-50:\n",
    "            self.xpos = self.dimx-50\n",
    "        if self.xpos < 000:\n",
    "            self.xpos = 000\n",
    "        if self.ypos > self.dimy-50:\n",
    "            self.ypos = self.dimy-50+1\n",
    "            self.gravityCurrent = 0\n",
    "            self.jumps = 0\n",
    "            \n",
    "    def display(self, gameDisplay):\n",
    "        if self.show:\n",
    "            pygame.draw.rect(gameDisplay, red, (self.xpos, self.ypos, AGENT_SIZE, AGENT_SIZE))\n",
    "    def act(self, agent_action):\n",
    "        # print(agent_action)\n",
    "        if agent_action == 0:\n",
    "            self.left()\n",
    "        elif agent_action == 1:\n",
    "            self.right()\n",
    "        elif agent_action == 2:\n",
    "            self.jump()\n",
    "        self.update()\n",
    "            \n",
    "\n",
    "class Env:\n",
    "    def __init__(self, \n",
    "                 game_dims=(1000, 800),\n",
    "                 show=False):\n",
    "        self.dimx, self.dimy = game_dims\n",
    "        self.agent = Agent((400,100), show=show, game_dims=game_dims)\n",
    "        self.set_default_rewards()\n",
    "        self.observation_space = 5\n",
    "        self.show = show\n",
    "        pygame.init()\n",
    "        self.play = True\n",
    "        \n",
    "        # GAME DIMENSIONS\n",
    "        self.game_dims = game_dims\n",
    "        self.generator_action_space = spaces.Box(np.array([0,0,0,0]), np.array([2,self.dimx,self.dimy,360]), dtype=np.float32)\n",
    "        self.agent_action_space = spaces.Discrete(3)\n",
    "        min_obs = np.array([0]*5 + [0,0,5,0]*5)\n",
    "        max_obs = np.array([2,self.dimx,self.dimy,1,self.dimy*2] + [self.dimx,self.dimy,50,360]*5)\n",
    "        self.observation_space = spaces.Box(min_obs, max_obs, dtype=np.float32)\n",
    "        \n",
    "        # DELAY FOR WEAPON ENTITIES\n",
    "        self.delay = 0\n",
    "#         self.entity_list = []\n",
    "        \n",
    "        self.entity_limit = 5\n",
    "        self.entity_free_keys = [0,1,2,3,4]\n",
    "        self.entity_dict = {}\n",
    "    def get_free_key(self):\n",
    "        if len(self.entity_free_keys) > 0:\n",
    "            return self.entity_free_keys.pop(0)\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    # CONTROL MOVEMENTS\n",
    "    def execute(self):\n",
    "        agent_action = None\n",
    "        weapon_action = (0,0,0)\n",
    "        \n",
    "        events = pygame.event.get()\n",
    "        for event in events:\n",
    "            if event.type == pygame.KEYDOWN:\n",
    "                if event.key == pygame.K_SPACE:\n",
    "                    agent_action = 2\n",
    "                if event.key == pygame.K_LEFT and self.agent.touchingObst == 0:\n",
    "                    agent_action = 0\n",
    "                if event.key == pygame.K_RIGHT and self.agent.touchingObst == 0:\n",
    "                    agent_action = 1\n",
    "            if event.type == pygame.QUIT:\n",
    "                pygame.display.quit()\n",
    "                agent_action = -1\n",
    "                \n",
    "        action = (agent_action, weapon_action)\n",
    "        return action\n",
    "            \n",
    "    def test_agent(self):\n",
    "        \"\"\"FOR TESTING OF AGENT ACTIONS ONLY\"\"\"\n",
    "        run = True\n",
    "        while run:\n",
    "            sleep(0.01)\n",
    "            action = self.execute()\n",
    "            if action == -1:\n",
    "                break\n",
    "            self.step(action)\n",
    "            \n",
    "    def create_entity(self, weapon_action):\n",
    "        # print(weapon_action)\n",
    "        wep_type, wep_x, wep_y, angle = weapon_action\n",
    "        wep_xy = (wep_x, wep_y)\n",
    "#         print(wep_xy)\n",
    "        if self.delay != 0:\n",
    "            self.delay -= 1\n",
    "#         wep_type = 1\n",
    "        if wep_type == 1 and self.delay == 0:\n",
    "            ent = Entity(str(wep_type), wep_xy, angle, 10)\n",
    "            ent_key = self.get_free_key()\n",
    "            if ent_key != None:\n",
    "                self.entity_dict[ent_key] = ent\n",
    "            self.delay = 20  # DELAY BEFORE THE NEXT ATTACK\n",
    "    def update_entities(self):\n",
    "        # UPDATE ENTITIES\n",
    "        collided = []\n",
    "        for key, ent in self.entity_dict.items():\n",
    "            collide = ent.update((self.agent.xpos, self.agent.ypos))\n",
    "            if not collide:\n",
    "                if self.show:\n",
    "#                     print(ent.x, ent.y)\n",
    "                    pygame.draw.rect(self.gameDisplay, blue, (ent.x, ent.y, WEAPON_SIZE, WEAPON_SIZE))\n",
    "            else:\n",
    "                self.agent.agent_reward = -20\n",
    "                self.generator_reward = 20\n",
    "                collided.append(key)\n",
    "        \n",
    "        for ent_key in collided:\n",
    "            self.entity_free_keys.append(ent_key)\n",
    "            del self.entity_dict[ent_key]\n",
    "    def display_game(self):\n",
    "        if self.show:\n",
    "#             print(self.game_dims)\n",
    "            self.gameDisplay = pygame.display.set_mode(self.game_dims, 0, 32)\n",
    "            self.gameDisplay.fill(white)\n",
    "    def display_background(self):\n",
    "        # DISPLAY BACKGROUND\n",
    "        if self.show:\n",
    "            pygame.font.init()\n",
    "            myFont = pygame.font.SysFont('Futura PT Light', 60)\n",
    "            textsurface = myFont.render('The Chosen One', False, black)\n",
    "            self.gameDisplay.blit(textsurface, (200,200))\n",
    "            pygame.display.update()\n",
    "    def set_default_rewards(self):\n",
    "        self.agent.agent_reward = 1\n",
    "        self.generator_reward = -1\n",
    "\n",
    "    def step(self, action):\n",
    "        # SET DEFAULT REWARDS FOR AGENT AND GENERATOR\n",
    "        self.set_default_rewards()\n",
    "        \n",
    "        # DISPLAY GAME\n",
    "        self.display_game()\n",
    "        \n",
    "        agent_action, weapon_action = action\n",
    "        \n",
    "        # MOVE THE AGENT\n",
    "        self.agent.act(agent_action)\n",
    "        if self.show:\n",
    "            self.agent.display(self.gameDisplay)\n",
    "        \n",
    "        # CREATE WEAPON ENTITY\n",
    "        self.create_entity(weapon_action)\n",
    "        \n",
    "        # UPDATE ENTITIES\n",
    "        self.update_entities()\n",
    "        \n",
    "        # DISPLAY BACKGROUND\n",
    "        self.display_background()\n",
    "        \n",
    "        \"\"\"RETURNS:\n",
    "        reward - (agent_reward, generator_reward)\n",
    "        state - getGameState()\n",
    "        done - CURRENT: DEFAULT: False\n",
    "        done - TODO: whether game is completed, e.g. HP <= 0\n",
    "        \"\"\"\n",
    "        reward = (self.agent.agent_reward, self.generator_reward)\n",
    "        state = self.getGameState()\n",
    "        \n",
    "        return (reward, state, False)\n",
    "        \n",
    "    def getGameState(self):\n",
    "        a = self.agent\n",
    "        agent_values = np.array([\n",
    "            a.jumps,\n",
    "            a.xpos//1000,\n",
    "            a.ypos//1000,\n",
    "            a.touchingObst,\n",
    "            a.gravityCurrent,\n",
    "            # TODO: height, width, dy, dx, direction, bounding box\n",
    "        ])\n",
    "        entity_values = np.array([])\n",
    "        for i in range(5):\n",
    "            if i in self.entity_dict:\n",
    "                e = self.entity_dict[i]\n",
    "                vals = [e.x//1000, e.y//1000, e.speed, e.angle]\n",
    "            else:\n",
    "                vals = [0,0,0,0]\n",
    "            entity_values = np.append(entity_values, vals)\n",
    "\n",
    "        values = np.append(agent_values, entity_values)\n",
    "        return values\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Resets the game. Returns (reward, state, done).\"\"\"\n",
    "        self.__init__(game_dims=self.game_dims, show=self.show)\n",
    "        return self.getGameState()\n",
    "\n",
    "    def test_step(self):\n",
    "        # Create Gun at random place and angles\n",
    "        agent_action = random.randint(0,2)\n",
    "\n",
    "        wep_type = 1  # gun\n",
    "        wep_xy = (50, 700)  # coordinate appears at\n",
    "        angle = 0\n",
    "\n",
    "        generator_action = (wep_type, wep_xy, angle)\n",
    "        action = (agent_action, generator_action)\n",
    "        self.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space: Box(25,)\n",
      "Agent action space: Discrete(3)\n",
      "Generator action space: Box(4,)\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n"
     ]
    }
   ],
   "source": [
    "env = Env(game_dims=(700, 500), show=False)\n",
    "\n",
    "# SHOW ENVIRONMENT VALUES\n",
    "print('Observation space:', env.observation_space)\n",
    "print('Agent action space:', env.agent_action_space)\n",
    "print('Generator action space:', env.generator_action_space)\n",
    "\n",
    "state = env.reset()\n",
    "print(\"State:\", state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 1.          0.          0.          0.         -9.5         0.\n",
      "  0.         10.         -0.34906585  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.        ]\n",
      "Done: False\n"
     ]
    }
   ],
   "source": [
    "# Create Gun at random place and angles\n",
    "agent_action = random.randint(0,2)\n",
    "\n",
    "wep_type = 1  # gun\n",
    "wep_xy = (50, 700)\n",
    "wep_x, wep_y = wep_xy\n",
    "angle = 20\n",
    "\n",
    "generator_action = (wep_type, wep_x, wep_y, angle)\n",
    "action = (agent_action, generator_action)\n",
    "reward, state, done = env.step(action)\n",
    "print(\"Agent Reward:\", reward[0])\n",
    "print(\"Generator Reward:\", reward[1])\n",
    "print(\"State:\", state)\n",
    "print(\"Done:\", done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR CONTINUOUS ACTION SPACE\n",
    "obs_space = env.observation_space\n",
    "obs_size = obs_space.low.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"AGENT HYPERPAREMETERS\"\"\"\n",
    "agent_action_space = env.agent_action_space\n",
    "agent_action_size = agent_action_space.n\n",
    "\n",
    "# Q FUNCTION AND ADAM OPTIMIZER\n",
    "agent_q_func = chainerrl.q_functions.FCStateQFunctionWithDiscreteAction(\n",
    "    obs_size, agent_action_size,\n",
    "    n_hidden_layers=5, n_hidden_channels=100)\n",
    "\n",
    "# Use Adam to optimize q_func. eps=1e-2 is for stability.\n",
    "agent_optimizer = chainer.optimizers.Adam(eps=1e-2)\n",
    "agent_optimizer.setup(agent_q_func)\n",
    "\n",
    "# Set the discount factor that discounts future rewards.\n",
    "agent_gamma = 0.95\n",
    "\n",
    "# Use epsilon-greedy for exploration\n",
    "agent_explorer = chainerrl.explorers.ConstantEpsilonGreedy(\n",
    "    epsilon=0.3, random_action_func=env.agent_action_space.sample)\n",
    "\n",
    "# DQN uses Experience Replay.\n",
    "# Specify a replay buffer and its capacity.\n",
    "agent_replay_buffer = chainerrl.replay_buffer.ReplayBuffer(capacity=10 ** 6)\n",
    "\n",
    "# Since observations from CartPole-v0 is numpy.float64 while\n",
    "# Chainer only accepts numpy.float32 by default, specify\n",
    "# a converter as a feature extractor function phi.\n",
    "agent_phi = lambda x: x.astype(np.float32, copy=False)\n",
    "\n",
    "# CHOSEN ONE AGENT\n",
    "chosen_one = chainerrl.agents.DoubleDQN(\n",
    "    agent_q_func, agent_optimizer, agent_replay_buffer, agent_gamma, agent_explorer,\n",
    "    replay_start_size=500, update_interval=1,\n",
    "    target_update_interval=100, phi=agent_phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"GENERATOR HYPERPARAMETERS\"\"\"\n",
    "generator_action_space = env.generator_action_space\n",
    "generator_action_size = generator_action_space.low.size\n",
    "\n",
    "# Q FUNCTION FOR CONTINUOUS VARIABLES\n",
    "generator_q_func = chainerrl.q_functions.FCQuadraticStateQFunction(\n",
    "    obs_size, generator_action_size,\n",
    "    n_hidden_layers=5,\n",
    "    n_hidden_channels=100,\n",
    "    action_space=generator_action_space,\n",
    ")\n",
    "\n",
    "# Use the Ornstein-Uhlenbeck process for exploration\n",
    "generator_ou_sigma = (generator_action_space.high - generator_action_space.low) * 0.2\n",
    "generator_explorer = explorers.AdditiveOU(sigma=generator_ou_sigma)\n",
    "\n",
    "# Use Adam to optimize q_func. eps=1e-2 is for stability.\n",
    "generator_optimizer = chainer.optimizers.Adam(eps=1e-2)\n",
    "generator_optimizer.setup(generator_q_func)\n",
    "\n",
    "# Set the discount factor that discounts future rewards.\n",
    "generator_gamma = 0.95\n",
    "\n",
    "# DQN uses Experience Replay.\n",
    "# Specify a replay buffer and its capacity.\n",
    "generator_replay_buffer = chainerrl.replay_buffer.ReplayBuffer(capacity=10 ** 6)\n",
    "\n",
    "# Since observations from CartPole-v0 is numpy.float64 while\n",
    "# Chainer only accepts numpy.float32 by default, specify\n",
    "# a converter as a feature extractor function phi.\n",
    "generator_phi = lambda x: x.astype(np.float32, copy=False)\n",
    "\n",
    "# GENERATOR AGENT\n",
    "generator = chainerrl.agents.DoubleDQN(\n",
    "    generator_q_func, generator_optimizer, generator_replay_buffer, generator_gamma, generator_explorer,\n",
    "    replay_start_size=500, update_interval=1,\n",
    "    target_update_interval=100, phi=generator_phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('average_q', 0), ('average_loss', 0), ('n_updates', 501719)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_one.load(\"chosen_one_model\")\n",
    "chosen_one.get_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('average_q', 0), ('average_loss', 0), ('n_updates', 501717)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.load(\"generator_model\")\n",
    "generator.get_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space: Box(25,)\n",
      "Agent action space: Discrete(3)\n",
      "Generator action space: Box(4,)\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n"
     ]
    }
   ],
   "source": [
    "env = Env(game_dims=(700, 500), show=True)\n",
    "\n",
    "# SHOW ENVIRONMENT VALUES\n",
    "print('Observation space:', env.observation_space)\n",
    "print('Agent action space:', env.agent_action_space)\n",
    "print('Generator action space:', env.generator_action_space)\n",
    "\n",
    "state = env.reset()\n",
    "print(\"State:\", state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.         10.\n",
      "  2.35619449]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.         10.\n",
      "  2.35619449]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.         10.\n",
      "  2.35619449]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.         10.\n",
      "  2.35619449]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.         10.\n",
      "  2.35619449]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.         10.\n",
      "  2.35619449]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.         10.\n",
      "  2.35619449]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.         10.\n",
      "  2.35619449]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.         10.\n",
      "  2.35619449]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.         10.\n",
      "  2.35619449]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.         10.\n",
      "  2.35619449]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.         10.\n",
      "  2.35619449]\n",
      "Done: False\n",
      "Agent Reward: -20\n",
      "Generator Reward: 20\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.         10.\n",
      "  2.35619449]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.         10.\n",
      "  2.35619449]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.         10.\n",
      "  2.35619449]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.         10.\n",
      "  2.35619449]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.         10.\n",
      "  2.35619449]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.         10.\n",
      "  2.35619449]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.         10.\n",
      "  2.35619449]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.         10.\n",
      "  2.35619449]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.         10.\n",
      "  2.35619449]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.         10.\n",
      "  2.35619449]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.         10.\n",
      "  2.35619449]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.         10.\n",
      "  2.35619449]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.         10.\n",
      "  2.35619449]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.         10.\n",
      "  2.35619449]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.         10.\n",
      "  2.35619449]\n",
      "Done: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.         10.\n",
      "  2.35619449]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.         10.\n",
      "  2.35619449]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.         10.\n",
      "  2.35619449]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.         10.\n",
      "  2.35619449]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.         10.\n",
      "  2.35619449]\n",
      "Done: False\n",
      "Agent Reward: -20\n",
      "Generator Reward: 20\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.        ]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.        ]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.        ]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.        ]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.        ]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.        ]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.        ]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.        ]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.        ]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.        ]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.        ]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.        ]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.         10.          2.35619449  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.        ]\n",
      "Done: False\n",
      "Agent Reward: -20\n",
      "Generator Reward: 20\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward: 1\n",
      "Generator Reward: -1\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n",
      "Agent Reward:"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-1091cd93ceda>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0magent_action\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerator_action\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Agent Reward:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Generator Reward:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"State:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\the-chosen-one\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    400\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m             \u001b[1;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    403\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m                 \u001b[1;31m# newlines imply flush in subprocesses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\the-chosen-one\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    203\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[1;31m# wake event thread (message content is ignored)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\the-chosen-one\\lib\\site-packages\\zmq\\sugar\\socket.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[0;32m    398\u001b[0m                                  copy_threshold=self.copy_threshold)\n\u001b[0;32m    399\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSocket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msend_multipart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg_parts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\the-chosen-one\\lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    sleep(0.003)\n",
    "    # Create Gun at random place and angles\n",
    "    agent_action = chosen_one.act(state)\n",
    "#     generator_action = generator.act(state)\n",
    "    wep_type = 0  # gun\n",
    "#     wep_xy = (random.randint(10,650), random.randint(10,490))\n",
    "    wep_xy = (500, 10)\n",
    "    wep_x, wep_y = wep_xy\n",
    "#     angle = (random.randint(0,360))\n",
    "    angle = -135\n",
    "\n",
    "    generator_action = (wep_type, wep_x, wep_y, angle)\n",
    "    action = (agent_action, generator_action)\n",
    "    reward, state, done = env.step(action)\n",
    "    print(\"Agent Reward:\", reward[0])\n",
    "    print(\"Generator Reward:\", reward[1])\n",
    "    print(\"State:\", state)\n",
    "    print(\"Done:\", done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Reward: -20\n",
      "Generator Reward: 20\n",
      "State: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Done: False\n"
     ]
    }
   ],
   "source": [
    "agent_action = chosen_one.act(state)\n",
    "#     generator_action = generator.act(state)\n",
    "wep_type = 0 # gun\n",
    "#     wep_xy = (random.randint(10,650), random.randint(10,490))\n",
    "wep_xy = (650, 460)\n",
    "wep_x, wep_y = wep_xy\n",
    "#     angle = (random.randint(0,360))\n",
    "angle = -180\n",
    "\n",
    "generator_action = (wep_type, wep_x, wep_y, angle)\n",
    "action = (agent_action, generator_action)\n",
    "reward, state, done = env.step(action)\n",
    "print(\"Agent Reward:\", reward[0])\n",
    "print(\"Generator Reward:\", reward[1])\n",
    "print(\"State:\", state)\n",
    "print(\"Done:\", done)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "the-chosen-one",
   "language": "python",
   "name": "the-chosen-one"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
